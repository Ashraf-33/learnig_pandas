{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "726491c6-42ca-4359-8d68-1c156cdd61b5",
   "metadata": {},
   "source": [
    "# Read CSV in pandas\n",
    "<b>read_csv() function in Pandas is used to read data from CSV files into a Pandas DataFrame.</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e4fcdf2-9678-4650-a942-d04ec3fbb4f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# simple code of read_csv()\n",
    "import pandas as pd\n",
    "df = pd.read_csv(r\"C:\\Users\\ASHRAF\\Downloads\\people_data (1).csv\")\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf7c712d-0cba-4390-bf82-717a41fed85a",
   "metadata": {},
   "source": [
    "# read_csv :\n",
    "<b>Syntax and parameter</b><br>\n",
    "<b>Syntax:</b><br> \n",
    "pd.read_csv(filepath_or_buffer, sep=' ,' , header='infer',  index_col=None, usecols=None, engine=None,skiprows=None,nrows=None)<br> \n",
    "\n",
    "<b>Parameters:</b> <br>\n",
    "\n",
    "<b>filepath_or_buffer:</b> Location of the csv file. It accepts any string path or URL of the file.<br>\n",
    "<b>sep:</b> It stands for separator, default is ', '.<br>\n",
    "<b>header:</b> It accepts int, a list of int, row numbers to use as the column names, and the start of the data.<br>\n",
    "If no names are passed, i.e., header=None, then, it will display the first column as 0, the second as 1, and so on.<br>\n",
    "<b>usecols:</b> Retrieves only selected columns from the CSV file.<br>\n",
    "<b>nrows:</b> Number of rows to be displayed from the dataset.<br>\n",
    "<b>index_col:</b> If None, there are no index numbers displayed along with records.<br>  \n",
    "<b>skiprows:</b> Skips passed rows in the new data frame."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e08659d-859f-4593-9d46-ff8134843c7f",
   "metadata": {},
   "source": [
    "<h1>Features in read_csv()</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edc4ed71-ee26-43f7-b5ee-8534f96b6dfd",
   "metadata": {},
   "source": [
    "<b>1. Read specific column using usecols</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c284679-4eda-4586-a2ad-2c09687ee9a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# only read last_name and their email on csv\n",
    "import pandas as pd\n",
    "read = pd.read_csv(\"https://media.geeksforgeeks.org/wp-content/uploads/20241121154629307916/people_data.csv\",\n",
    "                   usecols=[\"Last Name\",\"Email\"])\n",
    "print(read)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "496b0d7c-e8f0-41c8-a38f-970c88e62896",
   "metadata": {},
   "source": [
    "<b>2. Setting an index column(index_col)</b><br>\n",
    "can set one or more columns as the dataframe index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ad97341-4431-41aa-b699-a23b039d538c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting first name as a new index\n",
    "set_in = pd.read_csv(\"https://media.geeksforgeeks.org/wp-content/uploads/20241121154629307916/people_data.csv\",\n",
    "                    index_col=[\"First Name\"])\n",
    "print(set_in)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a097395a-1c29-409a-b5a3-59975edac92a",
   "metadata": {},
   "source": [
    "<b> if want to handle missing value.</b><br>\n",
    "# 3. Can use na_values\n",
    "as in this csv file there are not have any missing value so it not need now"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a85028c-58d1-4e02-b85d-8363cc3f5c2a",
   "metadata": {},
   "source": [
    "<b>4. nrows in read_csv()</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6fd1e70-8b12-4af5-b1ca-5e607edd9568",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "# creat  url and then call the csv \n",
    "url = \"https://media.geeksforgeeks.org/wp-content/uploads/20241121154629307916/people_data.csv\"\n",
    "# display only 5 rows\n",
    "call_row = pd.read_csv(url,nrows=3)\n",
    "print(call_row)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c81b2005-bd3b-42f7-bf76-a2ed8cc2b71b",
   "metadata": {},
   "source": [
    "<b>5. skiprows</b><br>\n",
    "it skip rows from the start of a file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a173dc1d-b611-4306-abe1-11f359bba063",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(url)\n",
    "print(\"previous csv file\\n\",data)\n",
    "# skip first 1 and 2 row \n",
    "new_data = pd.read_csv(url,skiprows=[1,2])\n",
    "print(\"new csv mpdified file\\n\",new_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42d19ca6-5842-4582-af64-e23cc9770b5d",
   "metadata": {},
   "source": [
    "<b>6. parse_dates in read_csv</b><br>\n",
    "The parse_dates parameter converts date columns into datetime objects,<br>\n",
    "simplifying operations like filtering, sorting, or time-based analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6513d6aa-6b52-4fc0-a6fd-0bacec9af24b",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_d = pd.read_csv(url,parse_dates=[\"Date of birth\"])\n",
    "print(p_d.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fff75b30-1bde-4a38-953f-db0447594297",
   "metadata": {},
   "source": [
    "# Saving pandas DataFrame as CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eb32100-c098-4fd2-b2d4-b0124538ee0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# making simple DataFrame\n",
    "import pandas as pd\n",
    "df = pd.DataFrame({\"Name\":[\"Alice\",\"Bob\",\"Stephen\",\"Jhon\"],\n",
    "                  \"Degree\":[\"MBA\",\"BSc\",\"BBA\",\"Phd\"],\n",
    "                  \"Score\":[90,80,85,70]})\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5636d45a-d9ad-402e-a1ed-1f83f5c852ca",
   "metadata": {},
   "source": [
    "<b>1. Export CSV to a Working Directory</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c917b51-898a-41f8-a942-a33c2193c4af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creat a csv file in this direcrtory\n",
    "df.to_csv(\"file1.csv\")\n",
    "# check the file\n",
    "t1 = pd.read_csv(\"file1.csv\")\n",
    "print(t1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6458701b-eed1-491f-a470-5ae59674d50f",
   "metadata": {},
   "source": [
    "<b>2. Saving CSV Without Headers and Index</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6c754e0-c030-4bd1-83e0-8749a6a0c9d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creat a csv file without headers and index \n",
    "df.to_csv(\"file2.csv\",header=False,index=False)\n",
    "# show this\n",
    "print(pd.read_csv(\"file2.csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a4752b9-e981-4e97-b11e-2e47babca446",
   "metadata": {},
   "source": [
    "<b>3.Save the CSV file to a Specified Location</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28d3e0c5-1145-45c4-a7cd-d29107a05679",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save this file in my pandas file\n",
    "df.to_csv(r\"C:\\Users\\ASHRAF\\OneDrive\\Desktop\\all_of_pandas\\file3.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06a6ab40-28e8-4905-9666-453fac172cc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to confirm this \n",
    "import os\n",
    "file_path =r\"C:\\Users\\ASHRAF\\OneDrive\\Desktop\\all_of_pandas\\file3.csv\"\n",
    "if os.path.exists(file_path):\n",
    "    print(\"Found this file\")\n",
    "else:\n",
    "    print(\"Not found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d395192b-fcb4-4d7a-8f17-921c46a63a48",
   "metadata": {},
   "source": [
    "<b>4. Write a DataFrame to CSV file using Tab Separator</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14a1a8f6-4653-482f-9c96-5a2f9de3df25",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"original datafram(df):\\n\",df)\n",
    "#modifie df with\"\\t\"using sep\n",
    "df.to_csv(\"file4.csv\",sep=\"\\t\",header=True,index=False)\n",
    "#print file4\n",
    "print(\"modified dataframe in csv:\\n\",pd.read_csv(\"file4.csv\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c72b63ca-f283-4d1e-ad13-1506488c471d",
   "metadata": {},
   "source": [
    "# Export pandas dataframe to CSV file\n",
    "<b>CSV = Comma-Separated Values</b><br>\n",
    "in pandas we use .to_csv to export a dataframe to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd8a00af-031f-4f91-9251-04badc20a73b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creat simple dataframe\n",
    "import pandas as pd\n",
    "df = pd.DataFrame({\"Name\":[\"a\",\"b\",\"c\",\"d\"],\n",
    "                  \"Score\":[90,80,85,70]})\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af167da8-2833-429c-9fed-6acacd742ccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# basic export \n",
    "df.to_csv(\"Name_score.csv\")\n",
    "# to check \n",
    "import os\n",
    "file_loc = \"Name_score.csv\"\n",
    "if os.path.exists(file_loc):\n",
    "    print(\"Found\")\n",
    "else:\n",
    "    print(\"Not Found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f72a2f68-f9ce-4d41-8090-80373cf96640",
   "metadata": {},
   "source": [
    "<b>Customizing the CSV Export</b><br>\n",
    "<b>1.Remove index column:</b> .to_csv(\"file.csv\",index=False)#if not remove index=True<br>\n",
    "<b>2. only selected column:</b> .to_csv(\"...\",columns=[])# in this [] give any column you want.<br>\n",
    "for example \"Name\" if you want only Name column.<br>\n",
    "<b>3. Exclude Header Row:</b> (,header=False)#if want header less or header=True.<br>\n",
    "<b>4.Handling Missing Values:</b> dataframe by default give 'NaN', if want to customize use ,na_rep(parameter).<br>\n",
    "<b>5. Change Column Separator:</b> csv use (,) by default.However in some cases other delimiters may be required such as<br>\n",
    "tabs (), semicolons (;), or pipes (|).\n",
    "Using a different delimiter can make the file more readable or compatible with specific systems."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00273fa3-c4c5-49f8-ab4d-b57dc73e5813",
   "metadata": {},
   "source": [
    "# Reading JSON files with pandas.\n",
    "JSON = JavaScript Object Notation <br>\n",
    "There are mainly three methods to read Json file using Pandas Some of them are:<br>\n",
    "<b>1. Using pd.read_json() Method</b><br>\n",
    "<b>2. Using JSON Module and pd.json_normalize() Method</b><br>\n",
    "<b>3. Using pd.Dataframe() Methods</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d616625-a6be-4b05-a6d2-bb7506b49cd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. pd.read_json()\n",
    "import pandas as pd\n",
    "df = pd.read_json(r\"C:\\Users\\ASHRAF\\Downloads\\file.json\")\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55ad37ef-afc6-46bf-818b-02d48ceb57cf",
   "metadata": {},
   "source": [
    "<b>2. Using json Module and pd.json_normalize() method:</b><br>\n",
    "The json_normalize() is used when we are working with nested JSON structues.<br>\n",
    "JSON from APIs often comes in nested form and this method helps to flatten it into a tabular format thatâ€™s easier to work<br> with in Pandas.This method is helpful when working with real-world JSON responses from APIs.\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c79db18-ff40-48ec-bb92-ef6464f0ce56",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "data = {\"One\":{\"0\":60,\"1\":60,\"2\":40,\"3\":50,\"4\":79,\"5\":90},\n",
    "       \"Two\":{\"0\":32,\"1\":444,\"2\":53,\"3\":78,\"4\":88,\"5\":43}}\n",
    "json_data = json.dumps(data)\n",
    "\n",
    "df_normalize = pd.json_normalize(json.loads(json_data))\n",
    "print(\"\\nDataFrame using JSON module and `pd.json_normalize()` method:\\n\",df_normalize)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aafd0f2a-1579-4cf7-8560-bb42141496ca",
   "metadata": {},
   "source": [
    "<b>3. Using pd.DataFrame with a Dictionary</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bee2bcd0-a8cb-4082-a893-f64c55646742",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d396d649-74f3-42d4-8fe3-da77f7072027",
   "metadata": {},
   "source": [
    "# Parsing JSON Dataset\n",
    "If you're fetching JSON from a web URL or API you'll also need requests.<br>\n",
    "like (import requests)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02dfb197-83c2-4428-96d6-f3c62287bd47",
   "metadata": {},
   "source": [
    "<b>Create a DataFrame and Convert It to JSON</b><br>\n",
    "<b>convert json file use .to_json()</b><br>\n",
    "JSON's orientations:<br>\n",
    "<b>orient='split':</b> separates columns, index and data clearly.<br>\n",
    "<b>orient='index':</b> shows each row as a key-value pair with its index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "391138e6-db02-41d3-8f37-fe3b9013852e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "#make simple dataframe\n",
    "df = pd.DataFrame([['a','b'],['c','d']],index=['row1','row2'],columns=['col1','col2'])\n",
    "print(df.to_json(orient='split'))\n",
    "print(df.to_json(orient='index'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42d3dcd3-df68-4dcf-b01e-47dc54598f6c",
   "metadata": {},
   "source": [
    "<h1>Read the JSON File directly from Web Data</h1><br>\n",
    "some function of requests class for read json file in pyhton:<br>\n",
    "<b>requests.get(url):</b> fetches data from the URL.<br>\n",
    "<b>response.json():</b> converts response to a Python dictionary/list.<br>\n",
    "<b>json_normalize():</b> converts nested JSON into a flat table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c27a4c2-6d82-4ab6-a045-a3855927b2b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "url =\"https://jsonplaceholder.typicode.com/posts\"\n",
    "response = requests.get(url)\n",
    "data = pd.json_normalize(response.json())\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89df3115-f900-480f-b946-6514ee029425",
   "metadata": {},
   "source": [
    "<h1>Handling Nested JSON in Pandas:</h1><br>\n",
    "nested JSON into a table use json_normalize() from pandas<br>\n",
    "making it easier to analyze or manipulate in a table format.<br>\n",
    "<b>json.load(f):</b>Loads the raw JSON into a Python dictionary.<br>\n",
    "<b>json_normalize(d['programs']):</b>Extracts the list under the programs key and flattens it into columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eac2eea7-e0c1-4e5e-ac4e-e87d2dc0e2f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from pandas import json_normalize\n",
    "with open(r\"C:\\Users\\ASHRAF\\OneDrive\\Desktop\\all_of_pandas\\raw_nyc_phil.json\") as f:\n",
    "    d = json.load(f)\n",
    "\n",
    "nycphil = json_normalize(d['programs'])\n",
    "nycphil.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eea1228-491b-4e15-93db-90beb6aa5b87",
   "metadata": {},
   "source": [
    "# Exporting Pandas DataFrame to JSON:\n",
    "Pandas a powerful Python library for data manipulationprovides the to_json() function<br>\n",
    "to convert a DataFrame into a JSON file and the read_json() function to read a JSON file into a DataFrame.<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10c068dd-68bc-4714-809a-3a13f5e5b737",
   "metadata": {},
   "outputs": [],
   "source": [
    "# exporting a simple dataframe\n",
    "import pandas as pd\n",
    "data = pd.DataFrame([['a','b','c'],['d','e','f'],['g','h','i']],\n",
    "                   index=['row1','row2','row3'],\n",
    "                   columns=['col1','col2','col3'])\n",
    "# convert to json\n",
    "data.to_json(\"file_json1.json\",orient=\"split\",compression=\"infer\",index=True)\n",
    "\n",
    "# read json file\n",
    "df = pd.read_json(\"file_json1.json\",orient=\"split\",compression=\"infer\")\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ef3a5a1-60fc-442e-b75b-3ab729e74f9f",
   "metadata": {},
   "source": [
    "<h1>JSON Orientations in Pandas:</h1><br>\n",
    "<b>1.records:</b> List of dictionaries.<br>\n",
    "<b>2.columns:</b>Dictionary with column labels.<br>\n",
    "<b>3.index:</b>Dictionary with row indices.<br>\n",
    "<b>4.split:</b>Dictionary with index, columns, and data.<br>\n",
    "<b>5.table:</b>JSON table schema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a9f5d5a-0420-4fd2-8f84-418024f0de9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(data=[\n",
    "    ['15135', 'Alex', '25/4/2014'],\n",
    "    ['23515', 'Bob', '26/8/2018'],\n",
    "    ['31313', 'Martha', '18/1/2019'],\n",
    "    ['55665', 'Alen', '5/5/2020'],\n",
    "    ['63513', 'Maria', '9/12/2020']],\n",
    "    columns=['ID', 'NAME', 'DATE OF JOINING'])\n",
    "\n",
    "df.to_json('file_json2.json', orient='split', compression='infer')\n",
    "\n",
    "df = pd.read_json('file_json2.json', orient='split', compression='infer')\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "001e0275-00cb-47a9-92af-c341db538c93",
   "metadata": {},
   "source": [
    "# Reading excel file using pandas.\n",
    "* To read excel file use<b>(pd.read_excel(\"file_name\"))</b><br>\n",
    "* If the excel file has multiple sheet use <b>.concat()</b> mathod.<br>to use this mathod first make different value for each sheet with<b> sheet_name,index_col</b><br>\n",
    "* To view 5 columns from the top and from the bottom of the data frame, we can run the command.<br><b> This head() and tail()</b>method also take arguments as numbers for the number of columns to show. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0c08c17-dd8c-4bc3-871b-81bf2db68563",
   "metadata": {},
   "source": [
    "<h2>Sort_values() method in Pandas:</h2><br>\n",
    "If any column contains numerical data, we can sort that column using the<b>variable.sort_values()</b> method.<br>\n",
    "<h2>Pandas Describe() method:</h2><br>\n",
    "Now, suppose our data is mostly numerical.<br>\n",
    "We can get the statistical information like mean, max, min, etc. about the data frame using the <b>variable.describe()</b> method.<br>\n",
    "<b>Note: it's as like as json or csv file.</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f4cf210-fe21-4176-a51f-aba70a9c819c",
   "metadata": {},
   "source": [
    "# Read Text Files with Pandas:\n",
    "Below are the methods by which we can read text files with Pandas:<br>\n",
    "<h2>Using read_csv()</h2>\n",
    "<h2>Using read_table()</h2>\n",
    "<h2>Using read_fwf()</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7457a208-fb9f-4b1f-b218-ac5b4be14705",
   "metadata": {},
   "source": [
    "<h1>1. using read_csv():</h1>\n",
    "<b>syntax:</b><br>\n",
    "data=pandas.read_csv('filename.txt', sep=' ', header=None, names=[\"Column1\", \"Column2\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bbf8420-d1a9-4dd3-9096-401834a82d10",
   "metadata": {},
   "source": [
    "<h1>2. using read_table():</h1>\n",
    "This function reads a general delimited file to a DataFrame object.<br> This function is essentially the same as the read_csv() function but with the delimiter = '\\t', instead of a comma by default.<br> \n",
    "<b>syntax:</b><br>\n",
    "     data=pandas.read_table('filename.txt', delimiter = ' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a91e7cc-1ddc-427f-b8e4-469c60e4789c",
   "metadata": {},
   "source": [
    "<h1>3. using read_fwf():</h1>\n",
    "this read_fwf() read the contents effectively into separate columns<br>\n",
    "<b>syntax:</b><br>\n",
    "data=pandas.read_fwf('filename.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24310b02-173c-4acb-8168-7a8c9f77726f",
   "metadata": {},
   "source": [
    "# can convert text file to csv file.\n",
    "1. first make a dataframe,<b>df=pd.read_csv(\"file.txt\",header=None,delimiter='/')</b><br>\n",
    "2. Then convert it like <b>df.to_csv(\"file_name\",index=...,header=...)</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34978023-09b8-4be4-bd6f-e95fe64f7693",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
